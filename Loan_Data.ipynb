{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternate Final Project for Robert Freid\n",
    "### Original Final Project Failed\n",
    "I made the mistake of choosing data sets that were not suitable for the Final Project. <br>\n",
    "I am attemting to pull toether something that is more flexible and usable for the assignment requirments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# python 3.10 or greater is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 10)\n",
    "\n",
    "# common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Sickit Learn imports\n",
    "## For pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "## For preprocessing\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder,\n",
    "    OrdinalEncoder,\n",
    "    StandardScaler\n",
    ")\n",
    "from sklearn.impute import(\n",
    "    SimpleImputer\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import (\n",
    "    LogisticRegression\n",
    ")\n",
    "\n",
    "## For model selection\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedShuffleSplit,\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    KFold,\n",
    "    GridSearchCV\n",
    ")\n",
    "\n",
    "# Classifier Algorithms\n",
    "from sklearn import metrics\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    BaggingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    VotingClassifier\n",
    ")\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# To plot figures\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import warnings\n",
    "import plotly.offline as pyo\n",
    "pyo.init_notebook_mode()\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 500)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# make notebook stable across runs\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfloan = pd.read_csv(\"data/Loan_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfloan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first five rows.\n",
    "dfloan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "dfloan.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicated rows.\n",
    "dfloan.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint: Successfully loaded dataset, found missing or null values, no duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfloan.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summation: 8 catagorical columns, 5 numerical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the describe() function results.\n",
    "dfloan.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the numerical dataset histograms for outliers and anomalies.\n",
    "dfloan.hist(bins = 50, figsize=(20,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summation of histograms.\n",
    "1.) Aplicant Income: Definitely has outliers and a majority of applicants income is centered around $5,000.00. <br>\n",
    "2.) Coapplicant Income: Essential the same as applicant income but luch less, with fewer outliers. <br>\n",
    "3.) Loan Amount: Loan amount just above 100 in number of applicants, tapers to the right. <br>\n",
    "4.) Loan Amount Term: Appears to be in months. Maybe need to consider alternative way to represent this data. <br>\n",
    "5.) Credit History: Appears to be either a 1 or 0, signifying that it is a simple has or has no credit history. <br>\n",
    "## Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the Loan_ID column it provides no important information.\n",
    "dfloan.drop(columns='Loan_ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the Loan_ID column has been droped from the datarframe.\n",
    "dfloan.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of rows.\n",
    "print('The total number of rows is: ', len(dfloan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the total number of columns.\n",
    "print('The total number of columns is: ', len(dfloan.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check again for the columns with null values.\n",
    "dfloan.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the value counts for each of the columns that have null or missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value_counts for the Gender column.\n",
    "display(dfloan['Gender'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender as a significant influencing catagory.\n",
    "There are only 13 out of 614 rows missing gender. <br>\n",
    "The ratio of men to women is 4-5 to 1. <br>\n",
    "There is little to no difference in credit scores between men and women. <br>\n",
    "Link: https://www.bankrate.com/personal-finance/debt/men-women-and-debt-does-gender-matter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Gender missing values with 'Female' value, not a significant edetermining element..\n",
    "dfloan['Gender'].fillna('Female', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value_counts for the Married column.\n",
    "display(dfloan['Married'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Married has only 3 missing values, and is not a significant influencing factor. \n",
    "The ratio of married to not married is approximately 2 to 1. <br>\n",
    "Married people tend ot be better risks when loaning money than unmarried. <br>\n",
    "Unmarried people tend to be a little more slopy and might miss this category. <br>\n",
    "I am changing the null values to No for this reasons to preserve the other data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Married missing values with 'No' \n",
    "dfloan['Married'].fillna('No', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value_counts for the Gender column.\n",
    "display(dfloan['Dependents'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Judging Dependents as factors in making Loans.\n",
    "There are 15 null values out of 614 rows. <br>\n",
    "Dependents above 3 is considered an increased risk in paying the loan back. <br>\n",
    "Link: https://www.nicheadvice.co.uk/how-children-affect-mortgage-applications/ <br>\n",
    "Therefore I am adding the 13 null values to the 3+ category attribute. <br>\n",
    "Individuals with more than 3 dependents would be most likely not to disclose that catagory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Dependents missing values with '3+' \n",
    "dfloan['Dependents'].fillna('3+', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value_counts for the Self_Employed column.\n",
    "display(dfloan['Self_Employed'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Employed value counts.\n",
    "There are 32 out of 614 rows that are missing values for self employed individuals. <br>\n",
    "Self employed individuals are usually very proud and are happy to admit that they are  independent. <br>\n",
    "On the other hand, if someone has a bad credit history, they would not disclose that value. <br>\n",
    "I am chaning the null values for Self_Employed to 'No' to preserve the rest of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Self_Employed missing values with 'No' \n",
    "dfloan['Self_Employed'].fillna('No', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value_counts for the Loan Amount column.\n",
    "display(dfloan['LoanAmount'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loan Amount has 22 missing values out of 614\n",
    "There are 203 different values for this catagory. <br>\n",
    "The loan amount could have a direct effect on the approval of the loan process. <br>\n",
    "And could impact the amount of risk the company is taking. <br>\n",
    "Best to eliminate these entries, which leave 592 records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop row values where null based on the LoanAmount column.\n",
    "dfloan.dropna(axis=0, subset=('LoanAmount'),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Loan_Amount_Term Value Counts\n",
    "display(dfloan['Loan_Amount_Term'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loan Amount Term has 14 missing values out of the remaining 592 records\n",
    "The most prevalent value is 360, or 30 year loan. <br>\n",
    "Not a significant factor in the ability to repay the loan. <br>\n",
    "Will make null values equal to 360."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill Loan_Amount_Term missing values with '360' \n",
    "dfloan['Loan_Amount_Term'].fillna(360, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Credit_History Value Counts\n",
    "display(dfloan['Credit_History'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The credit History column has the most na values with there being 50, out of 592\n",
    "If we reaplce the null values with 0, it will force a review of the loan to acquire history. <br>\n",
    "Replace null values with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace null values with 0.0\n",
    "dfloan['Credit_History'].fillna(0.0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summation of Null or Missing Values\n",
    "We should have 592 records. <br>\n",
    "We should have no null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check again for the columns with null values.\n",
    "dfloan.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Data Set Types \n",
    "Review the data set types and if necessary make changes to facilitate processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfloan.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emaploy the info to gather numerical information.\n",
    "dfloan.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfloan.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Data Types\n",
    "Gender is either 'Male' or 'Female'. Needs to be changed to either 1 or 0. <br>\n",
    "Married is a yes or a no, change to true or false? <br>\n",
    "Dependents and Education is OK. <br>\n",
    "Self_Employed needs to be changed from a string (yes, no) to binary (true, false) value. <br>\n",
    "Credit_History needs to be changed from a numeric 1, 0  to binary true,false values. <br>\n",
    "Loan_Status needs to be changed fro a string Y, N to binary True, False values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the Gender vales from Male, Female to 1, 0\n",
    "dfloan['Gender'] = dfloan['Gender'].map({'Male': 1, 'Female': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the Married column values from string, No and Yes to binary, true and false.\n",
    "dfloan['Married'] = dfloan['Married'].map({'Yes':True, 'No': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the Self_Employed column values from string, No and Yes to binary, true and false.\n",
    "dfloan['Self_Employed'] = dfloan['Self_Employed'].map({'Yes':True, 'No': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the Credit_Hsitory column values from numeric, 0, 1 to binary, true and false.\n",
    "dfloan['Credit_History'] = dfloan['Credit_History'].map({ 1:True, 0:False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the Loan_Status column values from string, Y, N to binary, true and false.\n",
    "dfloan['Loan_Status'] = dfloan['Loan_Status'].map({ 'Y':True, 'N':False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfloan.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfloan.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_corr = dfloan.corr()\n",
    "loan_corr['Loan_Status'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Correlation Matrix for dataset\n",
    "sns.heatmap(dfloan.corr(), cmap='BrBG');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting the Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_X = dfloan.drop('Loan_Status',axis=1)\n",
    "loan_y = dfloan['Loan_Status']\n",
    "X_train, X_test, y_train, y_test = train_test_split(loan_X, loan_y, test_size=0.2, random_state=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(loan_X.sample(3))\n",
    "display(loan_y.sample(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate the features from the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['Gender', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount', 'Loan_Amount_Term'];\n",
    "cat_features = ['Dependents', 'Education', 'Property_Area'];\n",
    "col_selector = ['Married', 'Self_Employed', 'Credit_History'];\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('scalar', StandardScaler())\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encode', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_features),\n",
    "    ('cat', cat_pipeline, cat_features),\n",
    "    ('pass', \"passthrough\", col_selector)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_prepared = full_pipeline.fit_transform(loan_X)\n",
    "\n",
    "column_names = [\n",
    "    feature\n",
    "        .replace('num__', '')\n",
    "        .replace('cat__', '')\n",
    "        .replace('pass__', '')\n",
    "    for feature in full_pipeline.get_feature_names_out()\n",
    "]\n",
    "\n",
    "loan_prepared = pd.DataFrame(loan_prepared, columns=column_names, index=loan_X.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the loan_prepared dataset\n",
    "loan_prepared.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze the Prepared Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_classifier = DummyClassifier(strategy='most_frequent')\n",
    "dummy_classifier.fit(loan_prepared, loan_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classifier score\n",
    "dummy_classifier.score(loan_prepared, loan_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use cross val score to get AUC score \n",
    "scores = cross_val_score(\n",
    "    dummy_classifier, loan_X, loan_y,\n",
    "    scoring = \"roc_auc\", cv=10\n",
    ") \n",
    "\n",
    "print(f\"Dummy Classifier  AUC: {scores.mean():.3f} STD: {scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model and Execute\n",
    "We have 592 rows, far below the 100K recommended level by sickit-learn for algorithm choice. <br>\n",
    "The ensemble models for this project are: Random Forest, Logistic Regression, Gradient Boosting, ADA Boosts, XG Boost, Voting Classification <br>\n",
    "KFold parameters are: n_splits = 10, random_state = 42, shuffle = True <br>\n",
    "Check for errors related to the cross val score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_prepared.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for model in [\n",
    "    RandomForestClassifier,\n",
    "    LogisticRegression,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    XGBClassifier\n",
    "]:\n",
    "    classifier_model = model()\n",
    "    kFold = KFold(\n",
    "        n_splits=10, random_state=42, shuffle=True\n",
    "    )\n",
    "    \n",
    "    scores = cross_val_score(\n",
    "        classifier_model,\n",
    "        loan_prepared,\n",
    "        loan_y,\n",
    "        scoring=\"roc_auc\", cv=kFold\n",
    "    )\n",
    "    print(\n",
    "        f\"{model.__name__:22}  AUC: {scores.mean():.3f}  STD: {scores.std():.2f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use confusion matrix display to visualize for the best model\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(loan_prepared, loan_y)\n",
    "\n",
    "metrics.ConfusionMatrixDisplay.from_estimator(\n",
    "    estimator=rf,\n",
    "    X=loan_prepared, y=loan_y,\n",
    "    cmap='Blues', colorbar=False\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use confusion matrix display to visualize for the best model\n",
    "lg = LogisticRegression()\n",
    "lg.fit(loan_prepared, loan_y)\n",
    "\n",
    "metrics.ConfusionMatrixDisplay.from_estimator(\n",
    "    estimator=lg,\n",
    "    X=loan_prepared, y=loan_y,\n",
    "    cmap='Blues', colorbar=False\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use confusion matrix display to visualize for the best model\n",
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(loan_prepared, loan_y)\n",
    "\n",
    "metrics.ConfusionMatrixDisplay.from_estimator(\n",
    "    estimator=gb,\n",
    "    X=loan_prepared, y=loan_y,\n",
    "    cmap='Blues', colorbar=False\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use confusion matrix display to visualize for the best model\n",
    "ada = AdaBoostClassifier()\n",
    "ada.fit(loan_prepared, loan_y)\n",
    "\n",
    "metrics.ConfusionMatrixDisplay.from_estimator(\n",
    "    estimator=ada,\n",
    "    X=loan_prepared, y=loan_y,\n",
    "    cmap='Blues', colorbar=False\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use confusion matrix display to visualize for the best model\n",
    "xg = XGBClassifier()\n",
    "xg.fit(loan_prepared, loan_y)\n",
    "\n",
    "metrics.ConfusionMatrixDisplay.from_estimator(\n",
    "    estimator=xg,\n",
    "    X=loan_prepared, y=loan_y,\n",
    "    cmap='Blues', colorbar=False\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier is the Model that Performed WELL\n",
    "We will see if we can improve on the prediction using the GridSearchCV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Employ these parameters to see if we can improve on the model and the accuracy.\n",
    "param_grid = {\n",
    "    'max_depth':[2],\n",
    "    'random_state':[0]\n",
    "}\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=1,\n",
    "    scoring=\"roc_auc\"\n",
    ").fit(loan_prepared,loan_y)\n",
    "print(f'Best Score: {grid_search.best_score_}')\n",
    "print(f'Best Params:  {grid_search.best_params_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Very slight improvement using GridSearchCV.\n",
    "Without: AUC: 0.731  STD: 0.06 <br>\n",
    "With: 0.7566"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the X_test and y_test data sets for completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The X_test dataset contains: ', X_test.sample(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The y_test dataset contains:  ', y_test.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the test set for comparison to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_test_set = full_pipeline.transform(X_test)\n",
    "\n",
    "column_names = [\n",
    "    feature\n",
    "        .replace('num__', '')\n",
    "        .replace('cat__', '')\n",
    "        .replace('pass__', '')\n",
    "    for feature in full_pipeline.get_feature_names_out()\n",
    "]\n",
    "\n",
    "loan_test_prepared = pd.DataFrame(transformed_test_set, columns=column_names, index=X_test.index)\n",
    "scores = cross_val_score(\n",
    "    rf, loan_test_prepared, y_test,\n",
    "    scoring = 'roc_auc', cv=10\n",
    ")\n",
    "print(\n",
    "    f'Random Forest Classifier  AUC:  {scores.mean():.3f}  STD:  {scores.std():.2f}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the Confusion Matrix for the best model for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.ConfusionMatrixDisplay.from_estimator(\n",
    "    estimator=rf,\n",
    "    X=loan_test_prepared, y=y_test,\n",
    "    cmap='Blues', colorbar=False\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***** End First Dataset - Begin Second Dataset *****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load second loan dataset called datacreditos.csv for second data set for analysis.\n",
    "dfloan2 = pd.read_csv('data/Credit_Data.csv')\n",
    "dfloan2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the ID column as it is not relevant to the outcome.\n",
    "dfloan2.drop(columns=['ID'], axis=1, inplace=True)\n",
    "dfloan2.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape.\n",
    "dfloan2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values.\n",
    "dfloan2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfloan2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the describe information.\n",
    "dfloan2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display in a histogrm information.\n",
    "dfloan2.hist(bins=50, figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valuecounts for columns of unknown row value variations.\n",
    "display(dfloan2['Loan_Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dfloan2['Gender'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dfloan2['Degree'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dfloan2['Citizenship'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfloan2.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summation of Dataset Before Splitting Data Set into Train and Test\n",
    "No null values. <br>\n",
    "Nominal Categrical Columns: Loan_Type, Gender, Degree, Citizenship <br>\n",
    "Numerical Columns: Age, Income, Credit_score, Signers, and Default (Target Column) <br>\n",
    "Histograms show a very even distribution of the data. <br>\n",
    "### Test Train Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_l2, test_set_l2 = train_test_split(dfloan2, test_size=0.2, random_state=42)\n",
    "train_set_l2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan2_X = train_set_l2.drop('Default', axis=1)\n",
    "loan2_y = train_set_l2['Default'].copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit ('3.10.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0ec0717219f9384a7d0e78bbbde4c520b6fd5aeb534ad0cbf257356617b8ec6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
